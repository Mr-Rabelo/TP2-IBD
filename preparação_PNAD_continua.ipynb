{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982d70b9-8c3e-41db-a8a1-172a6b4883f6",
   "metadata": {},
   "source": [
    "# Limpeza e Preparação dos microdados da PNAD contínua\n",
    "\n",
    "Este código Python é uma ferramenta para **consolidar e extrair dados específicos dos microdados da Pesquisa Nacional por Amostra de Domicílios Contínua (PNADC)**, disponibilizados pelo IBGE. Ele foi projetado para processar os arquivos de texto (`.txt`) de todos os trimestres de 2023 e gerar um único arquivo CSV (`.csv`) com as informações selecionadas, focando em características de **desemprego e educação**.\n",
    "\n",
    "---\n",
    "\n",
    "## Como o código funciona?\n",
    "\n",
    "O script pode ser dividido em três partes principais: configuração, preparação de dados e execução.\n",
    "\n",
    "### 1. Configuração\n",
    "\n",
    "Nesta seção, definimos os parâmetros essenciais para o funcionamento do script:\n",
    "\n",
    "* **`arquivos_txt_ibge`**: Uma lista com os nomes dos arquivos `.txt` dos microdados da PNADC para cada trimestre de 2023.\n",
    "* **`arquivo_csv_saida`**: O nome que você deseja dar ao arquivo CSV final, que conterá todos os dados consolidados.\n",
    "* **`colunas_selecionadas`**: Uma lista de tuplas que especifica as colunas que serão extraídas de cada arquivo `.txt`. Para cada coluna, é fornecido:\n",
    "    * O nome original da coluna (conforme o dicionário de variáveis da PNADC).\n",
    "    * A posição inicial da coluna no arquivo de texto (base 1).\n",
    "    * O tamanho (número de caracteres) da coluna.\n",
    "\n",
    "    Essas colunas são agrupadas por suas categorias: Identificação e Localização, Características Gerais dos Moradores, Características de Educação e Características de Trabalho (com foco em ocupação e desemprego).\n",
    "* **`mapeamento_nomes_colunas`**: Um dicionário que relaciona os nomes originais das colunas (geralmente códigos como \"V1023\") a nomes mais descritivos e fáceis de entender, como \"TIPO\\_AREA\". Isso torna o arquivo CSV final muito mais legível.\n",
    "\n",
    "### 2. Preparação dos Dados\n",
    "\n",
    "Antes de processar os arquivos, o código prepara as informações de coluna para que o pandas (uma biblioteca de manipulação de dados em Python) possa lê-las corretamente:\n",
    "\n",
    "* Ele cria `nomes_colunas_originais` com apenas os nomes das colunas que serão usadas.\n",
    "* Ele calcula as `posicoes_colunas` no formato que o pandas espera para leitura de arquivos de largura fixa (`colspecs`), convertendo a posição base 1 (humana) para base 0 (programação).\n",
    "\n",
    "### 3. Execução do Script\n",
    "\n",
    "Esta é a parte principal do código, onde a magia acontece:\n",
    "\n",
    "* **Loop de Processamento**: O script itera sobre cada arquivo TXT listado em `arquivos_txt_ibge`.\n",
    "* **Verificação de Existência**: Antes de tentar ler um arquivo, ele verifica se o arquivo realmente existe no diretório. Se não existir, emite um aviso e pula para o próximo arquivo.\n",
    "* **Leitura do Arquivo**: Utiliza a função `pd.read_fwf()` do pandas para ler os arquivos de texto de largura fixa. É importante notar o uso de `encoding='latin-1'`, que é um tipo de codificação comum para dados do IBGE e evita erros de leitura de caracteres especiais.\n",
    "* **Renomeação de Colunas**: Após a leitura, as colunas são renomeadas para os nomes mais descritivos definidos no `mapeamento_nomes_colunas`, melhorando a clareza dos dados.\n",
    "* **Consolidação em CSV**:\n",
    "    * Para o **primeiro arquivo** processado, o script **cria** um novo arquivo CSV (`arquivo_csv_saida`) e inclui o cabeçalho das colunas.\n",
    "    * Para os **arquivos subsequentes**, ele **adiciona** os dados ao mesmo arquivo CSV, mas **sem o cabeçalho**, garantindo que o arquivo final tenha apenas um conjunto de cabeçalhos.\n",
    "* **Tratamento de Erro de Memória**: O código inclui um bloco `try-except` para lidar com `MemoryError`. Se um arquivo for muito grande para ser carregado de uma vez na memória, o script tenta lê-lo em **blocos (chunks)** menores. Isso é crucial para lidar com grandes volumes de dados sem esgotar a memória RAM do computador.\n",
    "* **Mensagens de Progresso e Erro**: Durante todo o processo, o script exibe mensagens informativas sobre o progresso e, caso ocorra algum erro, uma mensagem detalhada é exibida para ajudar na depuração.\n",
    "\n",
    "---\n",
    "\n",
    "## Para que serve este código?\n",
    "\n",
    "Este script é extremamente útil para pesquisadores, analistas de dados e estudantes que precisam trabalhar com os microdados da PNADC do IBGE. Ele automatiza o processo de:\n",
    "\n",
    "* **Extração seletiva**: Não precisamos carregar o arquivo `.txt` inteiro e depois selecionar as colunas, o que economiza tempo e recursos computacionais.\n",
    "* **Consolidação de dados**: Facilita a análise de tendências anuais ao combinar dados de diferentes trimestres em um único arquivo.\n",
    "* **Limpeza e organização**: Os nomes de colunas descritivos melhoram a compreensibilidade e a usabilidade dos dados.\n",
    "* **Tratamento de grandes volumes de dados**: A capacidade de processar arquivos em chunks (pedações) permite lidar com datasets que seriam impossíveis de carregar completamente na memória.\n",
    "\n",
    "Ao final da execução, temos um arquivo CSV consolidado (`pnadc_2023_consolidado_desemprego_educacao.csv` neste exemplo) pronto para ser importado em ferramentas de análise de dados como Excel, Tableau, Power BI ou diretamente em outros scripts Python para análises mais aprofundadas. No nosso caso, usamos o Postgree SQL para fazer as consultas de interesse para o projeto.\n",
    "\n",
    "Esperamos que esta explicação detalhada ajude a entender o propósito e o funcionamento do código! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76902d46-5959-4c0c-8a05-55bf759ae598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento dos arquivos da PNAD Contínua...\n",
      "\n",
      "Processando o arquivo: PNADC_012023.txt (1/4)...\n",
      "Arquivo 'PNADC_012023.txt' lido com sucesso! Total de 473335 linhas.\n",
      "Dados de 'PNADC_012023.txt' adicionados a 'pnadc_2023_consolidado_desemprego_educacao.csv'.\n",
      "\n",
      "Processando o arquivo: PNADC_022023.txt (2/4)...\n",
      "Arquivo 'PNADC_022023.txt' lido com sucesso! Total de 474575 linhas.\n",
      "Dados de 'PNADC_022023.txt' adicionados a 'pnadc_2023_consolidado_desemprego_educacao.csv'.\n",
      "\n",
      "Processando o arquivo: PNADC_032023.txt (3/4)...\n",
      "Arquivo 'PNADC_032023.txt' lido com sucesso! Total de 479873 linhas.\n",
      "Dados de 'PNADC_032023.txt' adicionados a 'pnadc_2023_consolidado_desemprego_educacao.csv'.\n",
      "\n",
      "Processando o arquivo: PNADC_042023.txt (4/4)...\n",
      "Arquivo 'PNADC_042023.txt' lido com sucesso! Total de 473206 linhas.\n",
      "Dados de 'PNADC_042023.txt' adicionados a 'pnadc_2023_consolidado_desemprego_educacao.csv'.\n",
      "\n",
      "Todos os arquivos foram processados. O arquivo consolidado 'pnadc_2023_consolidado_desemprego_educacao.csv' foi criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os # Importar para verificar a existência de arquivos\n",
    "\n",
    "# --- Configure aqui ---\n",
    "\n",
    "# Lista dos arquivos de microdados TXT dos 4 trimestres de 2023\n",
    "# Adapte os nomes dos arquivos se forem diferentes\n",
    "arquivos_txt_ibge = [\n",
    "    'PNADC_012023.txt', # 1º Trimestre\n",
    "    'PNADC_022023.txt', # 2º Trimestre\n",
    "    'PNADC_032023.txt', # 3º Trimestre\n",
    "    'PNADC_042023.txt', # 4º Trimestre\n",
    "]\n",
    "\n",
    "# Diga qual o nome do arquivo CSV que você quer criar para a saída consolidada\n",
    "arquivo_csv_saida = 'pnadc_2023_consolidado_desemprego_educacao.csv'\n",
    "\n",
    "# Defina as colunas para extrair com base no dicionário fornecido e na análise proposta.\n",
    "# Formato: ('Nome da Coluna', Posição Inicial no arquivo (base 1), Tamanho)\n",
    "colunas_selecionadas = [\n",
    "    # Parte 1 - Identificação e Localização\n",
    "    ('Ano', 1, 4), # Ano de referência\n",
    "    ('Trimestre', 5, 1), # Trimestre de referência\n",
    "    ('UF', 6, 2), # Unidade da Federação\n",
    "    ('Capital', 8, 2), # Município da Capital\n",
    "    ('RM_RIDE', 10, 2), # Região Metropolitana e Região Administrativa Integrada de Desenvolvimento\n",
    "    ('V1023', 34, 1), # Tipo de área (Urbana/Rural)\n",
    "    ('V1027', 35, 15), # Peso do domicílio e das pessoas (com correção de não entrevista sem calibração)\n",
    "    ('V1028', 50, 15), # Peso do domicílio e das pessoas (com correção de não entrevista com calibração)\n",
    "\n",
    "    # Parte 2 - Características Gerais dos Moradores\n",
    "    ('V2005', 93, 2), # Condição no domicílio\n",
    "    ('V2007', 95, 1), # Sexo\n",
    "    ('V2009', 104, 3), # Idade do morador na data de referência\n",
    "    ('V2010', 107, 1), # Cor ou raça\n",
    "\n",
    "    # Parte 3 - Características de Educação\n",
    "    ('V3001', 108, 1), # Sabe ler e escrever?\n",
    "    ('V3002', 109, 1), # Frequenta escola?\n",
    "    ('V3009A', 125, 2), # Qual foi o curso mais elevado que ... frequentou anteriormente?\n",
    "    ('V3014', 135, 1), # Concluiu este curso que frequentou anteriormente?\n",
    "\n",
    "    # Parte 4 - Características de trabalho das pessoas (foco em ocupação e desemprego)\n",
    "    ('V4001', 136, 1), # Trabalhou ou estagiou remunerado em dinheiro?\n",
    "    ('V4002', 137, 1), # Trabalhou ou estagiou remunerado em produtos/mercadorias?\n",
    "    ('V4003', 138, 1), # Fez bico/trabalho ocasional remunerado?\n",
    "    ('V4004', 139, 1), # Ajudou trabalho não remunerado de morador/parente?\n",
    "    ('V4005', 140, 1), # Tinha trabalho remunerado do qual estava temporariamente afastado?\n",
    "    ('V403311', 199, 1), # Número da faixa de renda para a retirada em dinheiro\n",
    "    ('V403312', 200, 8), # Renda bruta mensal\n",
    "    ('V4071', 376, 1), # Tomou alguma providência para conseguir trabalho (30 dias)?\n",
    "    ('V4072A', 379, 1), # Qual foi a principal providência que tomou para conseguir trabalho?\n",
    "    ('V4073', 380, 1), # Gostaria de ter trabalho, mesmo sem procurar?\n",
    "    ('V4074A', 382, 2), # Qual foi o principal motivo de não ter tomado providência para conseguir trabalho?\n",
    "    ('V4078A', 396, 1), # Qual foi o principal motivo para ... não querer(poder começar a) trabalhar na semana de referência?\n",
    "]\n",
    "\n",
    "# Dicionário de mapeamento de nomes originais para nomes mais descritivos\n",
    "mapeamento_nomes_colunas = {\n",
    "    'Ano': 'ANO',\n",
    "    'Trimestre': 'TRIMESTRE',\n",
    "    'UF': 'UF',\n",
    "    'Capital': 'CAPITAL',\n",
    "    'RM_RIDE': 'REGIAO_METROP_RIDE',\n",
    "    'V1023': 'TIPO_AREA',\n",
    "    'V1027': 'PESO_DOMIC_S_CALIB',\n",
    "    'V1028': 'PESO_DOMIC_C_CALIB',\n",
    "    'V2005': 'CONDICAO_DOMICILIO',\n",
    "    'V2007': 'SEXO',\n",
    "    'V2009': 'IDADE',\n",
    "    'V2010': 'COR_RACA',\n",
    "    'V3001': 'SABE_LER_ESCREVER',\n",
    "    'V3002': 'FREQUENTA_ESCOLA',\n",
    "    'V3009A': 'CURSO_ELEVADO_ANTERIOR', # Alterado para o nome da nova coluna\n",
    "    'V3014': 'CONCLUIU_CURSO_ANTERIOR',\n",
    "    'V4001': 'TRAB_REMUN_DINHEIRO',\n",
    "    'V4002': 'TRAB_REMUN_PROD_MERC',\n",
    "    'V4003': 'FEZ_BICO_OCASIONAL',\n",
    "    'V4004': 'AJUDA_TRAB_NAO_REMUN',\n",
    "    'V4005': 'AFASTADO_TRAB_REMUN',\n",
    "    'V403311': 'FAIXA_RENDA',\n",
    "    'V403312': 'RENDA_BRUTA_MENSAL',\n",
    "    'V4071': 'PROCUROU_TRABALHO',\n",
    "    'V4072A': 'PRINC_PROVID_PROCURA', # Alterado para o nome da nova coluna\n",
    "    'V4073': 'GOSTARIA_TRAB_NAO_PROCURA',\n",
    "    'V4074A': 'MOTIVO_NAO_PROCURA', # Alterado para o nome da nova coluna\n",
    "    'V4078A': 'MOTIVO_NAO_COME_TRAB' # Alterado para o nome da nova coluna\n",
    "}\n",
    "\n",
    "\n",
    "# Prepara as listas para o pandas\n",
    "# Usamos os nomes originais para leitura e renomeamos depois\n",
    "nomes_colunas_originais = [col[0] for col in colunas_selecionadas]\n",
    "posicoes_colunas = []\n",
    "for col_name, start_pos_1_base, length in colunas_selecionadas:\n",
    "    start_pos_0_base = start_pos_1_base - 1\n",
    "    end_pos_0_base = start_pos_0_base + length\n",
    "    posicoes_colunas.append((start_pos_0_base, end_pos_0_base))\n",
    "\n",
    "# --- Execução do Script ---\n",
    "print(\"Iniciando processamento dos arquivos da PNAD Contínua...\")\n",
    "\n",
    "# Usaremos o modo de escrita 'w' para o primeiro arquivo (cria ou sobrescreve)\n",
    "# e o modo de apêndice 'a' para os arquivos seguintes.\n",
    "first_file = True\n",
    "\n",
    "for i, arquivo_txt_ibge_atual in enumerate(arquivos_txt_ibge):\n",
    "    print(f\"\\nProcessando o arquivo: {arquivo_txt_ibge_atual} ({i+1}/{len(arquivos_txt_ibge)})...\")\n",
    "\n",
    "    if not os.path.exists(arquivo_txt_ibge_atual):\n",
    "        print(f\"Aviso: O arquivo '{arquivo_txt_ibge_atual}' não foi encontrado e será pulado.\")\n",
    "        continue # Pula para o próximo arquivo se este não existir\n",
    "\n",
    "    try:\n",
    "        # Leitura direta do arquivo (para arquivos que cabem na RAM)\n",
    "        df_temp = pd.read_fwf(\n",
    "            arquivo_txt_ibge_atual,\n",
    "            colspecs=posicoes_colunas,\n",
    "            names=nomes_colunas_originais, # Usar os nomes originais para a leitura\n",
    "            encoding='latin-1' # Usar encoding correto, 'latin-1' é comum para dados do IBGE\n",
    "        )\n",
    "        print(f\"Arquivo '{arquivo_txt_ibge_atual}' lido com sucesso! Total de {len(df_temp)} linhas.\")\n",
    "\n",
    "        # Renomear as colunas do DataFrame usando o mapeamento\n",
    "        df_temp.rename(columns=mapeamento_nomes_colunas, inplace=True)\n",
    "        \n",
    "        if first_file:\n",
    "            # Se for o primeiro arquivo, cria o CSV e escreve o cabeçalho\n",
    "            df_temp.to_csv(arquivo_csv_saida, mode='w', index=False, header=True)\n",
    "            first_file = False\n",
    "        else:\n",
    "            # Para os arquivos seguintes, anexa ao CSV sem o cabeçalho\n",
    "            df_temp.to_csv(arquivo_csv_saida, mode='a', index=False, header=False)\n",
    "        \n",
    "        print(f\"Dados de '{arquivo_txt_ibge_atual}' adicionados a '{arquivo_csv_saida}'.\")\n",
    "\n",
    "    except MemoryError:\n",
    "        print(f\"Erro de memória ao carregar o arquivo '{arquivo_txt_ibge_atual}' completo. Tentando carregar em chunks...\")\n",
    "        # --- Carregamento em Chunks para Memória Limitada ---\n",
    "        chunk_size = 50000 # Experimente com 50.000, 100.000, etc.\n",
    "\n",
    "        first_chunk_for_file = True\n",
    "        for j, chunk_df in enumerate(pd.read_fwf(\n",
    "            arquivo_txt_ibge_atual,\n",
    "            colspecs=posicoes_colunas,\n",
    "            names=nomes_colunas_originais, # Usar os nomes originais para a leitura\n",
    "            chunksize=chunk_size,\n",
    "            encoding='latin-1'\n",
    "        )):\n",
    "            print(f\"Processando chunk {j+1} de '{arquivo_txt_ibge_atual}'...\")\n",
    "            \n",
    "            # Renomear as colunas do chunk usando o mapeamento\n",
    "            chunk_df.rename(columns=mapeamento_nomes_colunas, inplace=True)\n",
    "\n",
    "            if first_file and first_chunk_for_file:\n",
    "                chunk_df.to_csv(arquivo_csv_saida, mode='w', index=False, header=True)\n",
    "                first_file = False\n",
    "                first_chunk_for_file = False\n",
    "            else:\n",
    "                chunk_df.to_csv(arquivo_csv_saida, mode='a', index=False, header=False)\n",
    "        print(f\"Arquivo '{arquivo_txt_ibge_atual}' processado via chunks e dados adicionados a '{arquivo_csv_saida}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao processar '{arquivo_txt_ibge_atual}': {e}\")\n",
    "\n",
    "print(f\"\\nTodos os arquivos foram processados. O arquivo consolidado '{arquivo_csv_saida}' foi criado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
